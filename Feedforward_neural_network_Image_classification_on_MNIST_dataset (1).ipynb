{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feedforward neural network : Image classification on MNIST dataset",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0azQCVlCiR"
      },
      "source": [
        "# **Feedforward artificial neural network : Image classification on MNIST dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trOyfziVgETH"
      },
      "source": [
        "# Import modules\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZmZEVmTmQGH"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "#### Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gRy7rVvg_Sl"
      },
      "source": [
        "def load_data():\n",
        "    # Import MNIST dataset from openml\n",
        "    dataset = fetch_openml('mnist_784', version=1, data_home=None)\n",
        "\n",
        "    # Data preparation\n",
        "    raw_X = dataset['data']\n",
        "    raw_Y = dataset['target']\n",
        "    return raw_X, raw_Y\n",
        "\n",
        "raw_X, raw_Y = load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pKpQA1aP8wf",
        "outputId": "267979bd-177d-4d63-dee9-4286e3629e9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 70000 entries, 0 to 69999\n",
            "Columns: 784 entries, pixel1 to pixel784\n",
            "dtypes: float64(784)\n",
            "memory usage: 418.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEwXHBQh8r93"
      },
      "source": [
        "## Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT499lYakFjo"
      },
      "source": [
        "def clean_data(raw_X, raw_Y):\n",
        "\n",
        "    cleaned_X = raw_X.astype('float32')\n",
        "    cleaned_X /= 255\n",
        "    \n",
        "    num_classes = 10\n",
        "    cleaned_Y = keras.utils.to_categorical(raw_Y, num_classes)\n",
        "    \n",
        "    return cleaned_X, cleaned_Y\n",
        "\n",
        "cleaned_X, cleaned_Y = clean_data(raw_X, raw_Y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpfxuSt4nKUw"
      },
      "source": [
        "#### Data split\n",
        "\n",
        "- Split data into a train set (50%), validation set (20%) and a test set (30%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gjkRpwbkP1j"
      },
      "source": [
        "def split_data(cleaned_X, cleaned_Y):\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(cleaned_X, cleaned_Y, test_size=0.3, random_state=42)\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=2/7, random_state=42)\n",
        "\n",
        "    return X_val, X_test, X_train, Y_val, Y_test, Y_train\n",
        "\n",
        "X_val, X_test, X_train, Y_val, Y_test, Y_train = split_data(cleaned_X, cleaned_Y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRTFvCTzn12X"
      },
      "source": [
        "### Model\n",
        "\n",
        "#### Neural network structure\n",
        "- For this network, we'll use 2 hidden layers\n",
        "- Layer 1 should have 128 nodes, a dropout rate of 20%, and relu as its activation function\n",
        "- Layer 2 should have 64 nodes, a dropout rate of 20%, and relu as its activation function\n",
        "- The last layer should map back to the 10 possible MNIST class. Use softmax as the activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgoOjxY9ki_O"
      },
      "source": [
        "def build_model():\n",
        "    \n",
        "       model = Sequential([\n",
        "        Dense(128, activation='relu', name='layer1', input_shape=(784, )),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu', name='layer2'),\n",
        "        Dropout(0.2),\n",
        "        Dense(10, activation='softmax', name='layer3')\n",
        "      ])   \n",
        "     \n",
        "       return model\n",
        "\n",
        "model = build_model()\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqv4in2ZodVR"
      },
      "source": [
        "# Model compilation\n",
        "\n",
        "- Use categorical crossentropy as loss function\n",
        "\n",
        "# Model training\n",
        "- Use a batch size of 128, and train for 12 epochs\n",
        "- Use verbose training, include validation data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHD6wIDlk095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96203bd2-6944-4953-a0d6-12466dd47e24"
      },
      "source": [
        "def compile_model(model):\n",
        "    # TODO: compile the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, Y_train, X_val, Y_val):\n",
        "    # TODO: train the model\n",
        "    # DO NOT CHANGE THE INPUTS OR OUTPUTS TO THIS FUNCTION\n",
        "    history = model.fit(X_train, Y_train, batch_size = 128, epochs = 12, verbose=1, validation_data=(X_val, Y_val))\n",
        "    return model, history\n",
        "\n",
        "model = compile_model(model)\n",
        "model, history = train_model(model, X_train, Y_train, X_val, Y_val)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "274/274 [==============================] - 3s 7ms/step - loss: 0.5606 - accuracy: 0.8327 - val_loss: 0.2329 - val_accuracy: 0.9318\n",
            "Epoch 2/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.2446 - accuracy: 0.9283 - val_loss: 0.1631 - val_accuracy: 0.9506\n",
            "Epoch 3/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.1844 - accuracy: 0.9441 - val_loss: 0.1366 - val_accuracy: 0.9589\n",
            "Epoch 4/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.1502 - accuracy: 0.9543 - val_loss: 0.1240 - val_accuracy: 0.9635\n",
            "Epoch 5/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.1256 - accuracy: 0.9612 - val_loss: 0.1154 - val_accuracy: 0.9647\n",
            "Epoch 6/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.1116 - accuracy: 0.9653 - val_loss: 0.1088 - val_accuracy: 0.9675\n",
            "Epoch 7/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.0952 - accuracy: 0.9703 - val_loss: 0.1071 - val_accuracy: 0.9692\n",
            "Epoch 8/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.0892 - accuracy: 0.9719 - val_loss: 0.1029 - val_accuracy: 0.9701\n",
            "Epoch 9/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.0799 - accuracy: 0.9743 - val_loss: 0.0992 - val_accuracy: 0.9707\n",
            "Epoch 10/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.0685 - accuracy: 0.9783 - val_loss: 0.0973 - val_accuracy: 0.9720\n",
            "Epoch 11/12\n",
            "274/274 [==============================] - 2s 7ms/step - loss: 0.0660 - accuracy: 0.9789 - val_loss: 0.1017 - val_accuracy: 0.9711\n",
            "Epoch 12/12\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.0960 - val_accuracy: 0.9733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6wzs18_ormL"
      },
      "source": [
        "# Model evaluation\n",
        "- Show the performance on the test set\n",
        "- What is the difference between \"evaluate\" and \"predict\"?\n",
        "- Identify a few images the model classifies incorrectly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxrqJb9Uk3Hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d6fcd1-4845-44fb-d505-a0d38dcb110a"
      },
      "source": [
        "def eval_model(model, X_test, Y_test):\n",
        "\n",
        "    score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "    test_loss = score[0] \n",
        "    test_accuracy = score[1]\n",
        "    print('Test Loss:', '%.4f' % test_loss)\n",
        "    print('Test Accuracy:', '%.4f' % test_accuracy)\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "test_loss, test_accuracy = eval_model(model, X_test, Y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "657/657 [==============================] - 2s 3ms/step - loss: 0.0920 - accuracy: 0.9735\n",
            "Test Loss: 0.0920\n",
            "Test Accuracy: 0.9735\n"
          ]
        }
      ]
    }
  ]
}